{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/sahaider/AppData/Local/Programs/Microsoft VS Code\n",
      "/mnt/d/Sajjad/08-2023/Python Code/Text Analytics - Spring 2024\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "#change working directory to the location of the data file\n",
    "os.chdir('/mnt/d/Sajjad/08-2023/Python Code/Text Analytics - Spring 2024/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 09:16:53.532373: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-01 09:16:53.745456: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-01 09:16:53.745493: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-01 09:16:53.746309: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-01 09:16:53.843180: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n"
     ]
    }
   ],
   "source": [
    "# Note: The default behavior now has injection attack prevention off.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-1_8B-Chat\", trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen-1_8B-Chat-Int4\", #\"Qwen/Qwen-7B-Chat-Int4\",\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving class example using Qwen LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last sentence of each example is classified as:  - \"not nice\": negative -\n",
      "\"very cold\": negative - \"cold\": negative - \"not nice\": negative - \"not very\n",
      "cold\": negative - \"nice weather\": positive\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Classify the last sentence using the following examples.\n",
    "\n",
    "<sentence>: it is nice weather \n",
    "<sentiment>: positive\n",
    "<sentence>: it is cold \n",
    "<sentiment>: negative\n",
    "<sentence>: it is not very cold \n",
    "<sentiment>: positive\n",
    "<sentence>: not nice \n",
    "<sentiment>: negative\n",
    "<sentence>: very cold \n",
    "<sentiment>: negative\n",
    "<sentence>: cold \n",
    "<sentiment>: negative\n",
    "<sentence>: very nice weather \n",
    "<sentiment>: positive\n",
    "<sentence>: it is not nice cold at all\n",
    "\n",
    "\"\"\"\n",
    "response, history = model.chat(tokenizer, prompt, history=None)\n",
    "print(textwrap.fill(response, width=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"it is nice weather \", \"it is cold \", \"it is not very cold \", \"not nice \", \"very cold \", \"cold \", \"very nice weather \", \"it is not nice cold at all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"it is not nice cold at all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PLM (bert-finetune-sst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  NEGATIVE  0.999766"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\")\n",
    "outputs = classifier(text)\n",
    "pd.DataFrame(outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is nice weather  POSITIVE 0.9998561143875122\n",
      "it is cold  NEGATIVE 0.9996206760406494\n",
      "it is not very cold  POSITIVE 0.9659685492515564\n",
      "not nice  NEGATIVE 0.9997665286064148\n",
      "very cold  NEGATIVE 0.999714195728302\n",
      "cold  NEGATIVE 0.9997304081916809\n",
      "very nice weather  POSITIVE 0.9998589754104614\n",
      "it is not nice cold at all NEGATIVE 0.9997656941413879\n"
     ]
    }
   ],
   "source": [
    "for s in sentences:\n",
    "    outputs = classifier(s)\n",
    "    print(s, outputs[0]['label'], outputs[0]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Qwen to evaluate all the 8 comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : it is nice weather \n",
      "Based on the given text, it is difficult to determine whether the sentiment is\n",
      "positive or negative without more context. It is a simple statement about\n",
      "pleasant weather, so it's unlikely to be very nuanced or expressing strong\n",
      "emotions. Therefore, I would rate the sentiment as neutral and provide a\n",
      "probability of 50% that my answer is correct.\n",
      "----------------------------------\n",
      "1 : it is cold \n",
      "Based on the given text, the sentiment can be classified as \"negative.\" The word\n",
      "\"cold\" typically has a negative connotation and can evoke feelings of discomfort\n",
      "or inconvenience. Therefore, the probability of the sentiment being positive\n",
      "would depend on other factors such as context and personal preferences.\n",
      "----------------------------------\n",
      "2 : it is not very cold \n",
      "The sentiment of the text is negative. The word \"not very cold\" indicates that\n",
      "the temperature is not pleasant and may be causing discomfort or inconvenience.\n",
      "The use of triple backticks also suggests that the text may be enclosed within\n",
      "an HTML code block. Based on these factors, the probability of a positive\n",
      "sentiment would be low, as the statement expresses a neutral or slightly\n",
      "negative opinion about the weather.\n",
      "----------------------------------\n",
      "3 : not nice \n",
      "Based on the given text, I would say that it has a negative sentiment. The use\n",
      "of triple backticks indicates that the text is being punctuated as code rather\n",
      "than as text, which could suggest a lack of confidence in the writer's opinion\n",
      "or intention. Additionally, the words \"not nice\" alone convey a negative\n",
      "impression. Therefore, the sentiment of the text can be classified as\n",
      "\"negative\".   Probability: 100%\n",
      "----------------------------------\n",
      "4 : very cold \n",
      "The sentiment of the given text can be considered negative because it contains\n",
      "the words \"cold\", which generally have a negative connotation.   As for the\n",
      "probability of my answer being positive, I would need more context to provide an\n",
      "accurate answer. The text provided does not convey any positive sentiment, and\n",
      "without additional information, it is difficult to determine whether it is\n",
      "intended to be positive or negative.\n",
      "----------------------------------\n",
      "5 : cold \n",
      "Based on the given text, it seems that the sentiment is negative because it\n",
      "describes something as \"cold\", which generally has a negative connotation.\n",
      "Therefore, my answer to this question would be \"negative\". The probability of\n",
      "this answer would depend on various factors such as the context in which the\n",
      "text was written and the individual's personal experience with cold\n",
      "temperatures. However, based solely on the given text, I would rate its\n",
      "sentiment as negative.\n",
      "----------------------------------\n",
      "6 : very nice weather \n",
      "Based on the text provided, I would say that the sentiment is positive. The use\n",
      "of double backticks around \"very nice weather\" indicates that the speaker is\n",
      "expressing satisfaction or approval for the weather conditions. Additionally,\n",
      "the lack of any negative language or tone suggests that the sentiment is\n",
      "positive. Therefore, my probability of the answer being positive is high.\n",
      "----------------------------------\n",
      "7 : it is not nice cold at all\n",
      "Based on the given text, it appears to be expressing negative sentiment. The\n",
      "phrase \"not nice\" implies dissatisfaction or discomfort.  The sentiment score\n",
      "for this text can vary depending on how the sentiment is expressed. In general,\n",
      "programming languages use sentiment analysis tools to determine the sentiment of\n",
      "a piece of text. However, without additional context or information about the\n",
      "language used in the text, it is difficult to provide an exact sentiment score.\n",
      "In this case, since there is no language provided and we are only considering\n",
      "text enclosed in triple backticks, the sentiment score would likely be low.\n",
      "Therefore, the answer could be either \"negative\" or \"low\", but without more\n",
      "information, it is difficult to assign a specific probability.\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, s in enumerate(sentences):\n",
    "    text = s\n",
    "    print(i, \":\", text)\n",
    "    prompt = f\"\"\"\n",
    "    What is the sentiment of the following text, which is delimited with triple backticks?\n",
    "\n",
    "    Give your answer as either \"positive\" or \"negative\". If possible, also share the probability of your answer.\n",
    "    Review text: '''{text}'''\n",
    "    \"\"\"\n",
    "    response, history = model.chat(tokenizer, prompt, history=None)\n",
    "    print(textwrap.fill(response, width=80))\n",
    "    print(\"----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "with open('corpus.txt','r',encoding=\"utf8\") as f:\n",
    "    document = f.readlines()\n",
    "f.close()\n",
    "\n",
    "labels, texts = [], []\n",
    "for line in document:\n",
    "    content = line.split()\n",
    "    label = content[0]\n",
    "    labels.append(label[-1])\n",
    "    texts.append(\" \".join(content[1:]))\n",
    "\n",
    "print(len(labels), len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^',\n",
       " \"The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\",\n",
       " 'Amazing!: This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you\\'ve played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time\\'s Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.',\n",
       " \"Excellent Soundtrack: I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Unstealable Jewel.Overall, this is a excellent soundtrack and should be brought by those that like video game music.Xander Cross\",\n",
       " \"Remember, Pull Your Jaw Off The Floor After Hearing it: If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '2', '2', '2', '2', '2', '1', '2', '2', '2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing BoW using CountVectorizer and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 31627)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer()\n",
    "features = cnt_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "features_nd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.846"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7156"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=100)\n",
    "features = cnt_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7384"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=200)\n",
    "features = cnt_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8024"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=500)\n",
    "features = cnt_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8264"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=2000)\n",
    "features = cnt_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8228"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 5),max_features=2000)\n",
    "features = cnt_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8432"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 3),max_features=5000)\n",
    "features = cnt_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 31627)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.838"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()#(ngram_range=(1, 3),max_features=5000)\n",
    "features = tfidf_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8456"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3),max_features=5000)\n",
    "features = tfidf_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RandomForestClassifier()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = KNeighborsClassifier()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train, y_test  = train_test_split(texts, labels, train_size=0.75,random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating all 2500 test records using PLM (bert-finetuned-sst)\n",
    "\n",
    "This may take upto 2-3 minutes on your local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pred = []\n",
    "for s in X_test2:\n",
    "    outputs = classifier(s)\n",
    "    bert_pred.append(outputs[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map 'Positive' to 2 and 'Negative' to 1 in bert_pred list \n",
    "bert_pred2 = []\n",
    "for s in bert_pred:\n",
    "    if s == 'POSITIVE':\n",
    "        bert_pred2.append('2')\n",
    "    else:\n",
    "        bert_pred2.append('1')\n",
    "accuracy_score(y_test, bert_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take top 100 records from X_test2\n",
    "X_test2a = X_test[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qwen and Zephyr can't be done on local machines (specially laptops) and should be done on Cloud"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
